import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score\nimport joblib\n\n# Load dataset\ndf = pd.read_csv('heart_disease_data.csv')  # Adjust the filename as necessary\n\n# Advanced preprocessing\ndf.fillna(method='ffill', inplace=True)  # Fill missing values\n\n# Feature engineering\ndf['age_squared'] = df['age'] ** 2  # Example feature\n\n# Define features and target variable\nX = df.drop('target', axis=1)\ny = df['target']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Preprocessing pipeline\nnumerical_features = X.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X.select_dtypes(include=['object']).columns\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', StandardScaler(), numerical_features),\n        ('cat', OneHotEncoder(), categorical_features)\n    ]\n)\n\n# Model pipeline\nmodels = {\n    'RandomForest': RandomForestClassifier(),\n    'GradientBoosting': GradientBoostingClassifier()\n}\n\n# Hyperparameter tuning and model training\nbest_model = None\nbest_accuracy = 0\n\nfor model_name, model in models.items():\n    pipeline = Pipeline([('preprocessor', preprocessor), ('classifier', model)])\n    param_grid = {\n        'classifier__n_estimators': [100, 200],\n        'classifier__max_depth': [None, 10, 20],\n    }\n    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n    grid_search.fit(X_train, y_train)\n    accuracy = accuracy_score(y_test, grid_search.predict(X_test))\n    print(f'{model_name} Accuracy: {accuracy:.2f}')\n    if accuracy > best_accuracy:\n        best_accuracy = accuracy\n        best_model = grid_search.best_estimator_\n\n# Save the best model\nif best_model:\n    joblib.dump(best_model, 'best_model.pkl')\n    print(f'Best model saved with accuracy: {best_accuracy:.2f}')\nelse:\n    print('No model achieved the desired accuracy.')